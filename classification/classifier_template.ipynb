{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/wangxiaonan/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import logging\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import json\n",
    "import requests\n",
    "import base64 \n",
    "import Levenshtein as lev\n",
    "import yaml\n",
    "import unicodedata\n",
    "from datetime import datetime, timedelta\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/1.csv', encoding='utf-8')\n",
    "df1, df2 = df[df['col']==1],df[df['col']==2]\n",
    "df1, df2 = df1.assign(label=0), df1.assign(label=1)\n",
    "data = pd.concat([df1, df2]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112016 112016 48008 48008 68583 68583\n"
     ]
    }
   ],
   "source": [
    "# split to train, val and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size=0.3, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "print(len(X_train),len(y_train),len(X_val),len(y_val),len(X_test),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text to features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=100000, ngram_range=(2,2))\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_val, X_test = vectorizer.transform(X_val), vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,auc,roc_auc_score\n",
    "# import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#define a function for performance metrics\n",
    "def model_train_eval(model,X_train,y_train, X_test,y_test):\n",
    "    print (model)\n",
    "    model.fit(X_train,y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    print (\"prediciton Accuracy : %f\" % accuracy_score(y_test, pred))\n",
    "    print (\"Confusion_matrix : \")\n",
    "    print (confusion_matrix(y_test,pred))\n",
    "    print (\"classification report : \")\n",
    "    print (classification_report(y_test, pred, labels=[0, 1]))\n",
    "        \n",
    "    if not str(model)[:3] == \"SGD\":\n",
    "        pred_proba = model.predict_proba(X_test)\n",
    "        pred_proba_c1 = pred_proba[:,1]\n",
    "        print (\"AUC Score : %f\" % roc_auc_score(y_test, pred_proba_c1))\n",
    "    return model\n",
    "\n",
    "def model_test_eval(y_test, pred, pred_proba=None):\n",
    "    print (\"prediciton Accuracy : %f\" % accuracy_score(y_test, pred))\n",
    "    print (\"Confusion_matrix : \")\n",
    "    print (confusion_matrix(y_test,pred))\n",
    "    print (\"classification report : \")\n",
    "    print (classification_report(y_test, pred, labels=[0, 1]))\n",
    "        \n",
    "    if pred_proba is not None and sum(y_test) not in (len(y_test), 0):\n",
    "        print (\"AUC Score : %f\" % roc_auc_score(y_test, pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "NB = MultinomialNB()\n",
    "LRcv = LogisticRegressionCV(solver=\"libnear\",penalty = \"l1\",cv = 5,random_state = 42,verbose=2,\n",
    "                           max_iter=5, class_weight='balanced')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_train_eval(LRcv, X_train, y_train, X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56079   137]\n",
      " [ 1051 11316]]\n"
     ]
    }
   ],
   "source": [
    "pred, pred_proba = model.predict(X_test), model.predict_proba(X_test)\n",
    "model_test_eval(y_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/vectorizer_v1_2gram.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(vectorizer, 'model/vectorizer_v1_2gram.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/lr_v1_2gram.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model, 'model/lr_v1_2gram.joblib') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
